# 360iDev 2016
Denver, CO

## [Debugging And Xcode – tips and advice](http://360idev.com/sessions/debugging-xcode-tips-advice/)
Kendall Gelner: [@kendalldevdiary](https://twitter.com/kendalldevdiary)

* Visual debugger buttons below view:
	* Show Clipped Views
	* Show Constraints
* Flex
	* Toolbar to view details about views

## [Teaching an iPhone to See: Adventures in Computer Vision](http://360idev.com/sessions/200-teaching-iphone-see-adventures-computer-vision/)
* Michael Schneider
* Hivebrain Software
* [Sample cascade classifier code](https://github.com/hivebrain/cascadeclassifierdemo)

Notes:

* Problem: recognize indicators in a Counter Strike radar HUD
* [TensorFlow](https://www.tensorflow.org/)
* [OpenCV](http://opencv.org/)
* Other choices
	* Convolutional neural network: deep learning
	* Template matching: match a known image, not good with variance
	* Contour matching: matching curves? edge detection
	* Cascade classifier: facial recognition. Been around for a long time, runs fast
		* Starts with a rough and quick test
		* If the image passes, cascades on to the next, more-specific test
		* An algorithm may have 30-50 of these stages
		* Only detects a face if all stages pass
		* Example: does the image have an eye? If yes: does it have a nose? If yes: does it have a mouth? etc
* The gist of how it works:
	* Import OpenCV
	* Use .mm file extension for Objective-C++
	* Load classifier
	* Start a video camera from CvVideoCamera, giving it an image view to display in
	* Give it a delegate, for camera permissions
	* `processImage:` delegate method called for each frame of the video
	* `filter:` method: boost the red to make it easier to identify red dots in the image
* Caveat: only works on grayscale images
* Edge detection is real easy
* Ultimately took about 20k good and 20k bad images to reliably detect
* Lessons learned
	* Smaller images (32x32) train faster

## [The Selfie Developer](http://360idev.com/sessions/100-selfie-developer/)
Steve Scott

## [Compilers aren’t magic, so let’s build one in Swift](http://360idev.com/sessions/300-compilers-arent-magic-lets-build-one-swift/)
* Ben DiFrancesco
	* [GitHub](https://github.com/apbendi)
	* [Twitter](http://twitter.com/bendifrancesco)
* How it works:
	* Define a source 
	* Choose a target language
	* Read stream of source characters
	* Break characters into language components
	* Process instructions in source language
	* Generate instructions in target language
	* Write and finalize source of target language
* Define a source
	* Bitsy: http://github.com/apbendi/bitsyspec
* Define a target language
	* For our purposes: Swift is the target language
* Read stream of source characters and break into language components
	* Tokenization
	* Tokens need two pieces of info
		* Kind of language element it references
		* Original characters from the source
	* Token types:
		* One type, arbitrary value: like an integer
		* Multiple types, specific values: such as keywords like BEGIN or END
	* Tokenizer: walks over stream of characters, returns a stream of tokens
* Process instructions in source language: parsing
	* Succeed if the program is valid, fail if invalid
	* Grammar: definition of set of valid programs
		* For simplest Bitsy program: `BEGIN ws {ws} END`
	* `Program = BEGIN <block> END`
	* `<block> = { <loop> | <break> }`
	* `<loop = LOOP <block> END`
	* `<break> = BREAK`
* Generate instructions in the target language
	* Code generation: produce code in the target language that has the same effects as those expressed in the source language
		* For example, in the parsing for a loop: `print("while true {")`, then parse the block of the loop, then `print("}")`
	* More complex parsing: less literal, more mechanistic. Use token values in code generation.


